# Configuration for Telegraf agent
[agent]
  ## Default data collection interval for all inputs
  interval = "5s"
  omit_hostname = true
  precision = "1ms"
  flush_interval = "5s"
  logfile = "${TELEGRAF_LOG_FILE}"

[[inputs.prometheus]]
  name_override = "metrics_questdb"
  ## An array of urls to scrape metrics from.
  urls = ["${QUESTDB_METRICS_ENDPOINT}"]
  url_tag=""
  metric_version = 2 # all entries will be on a single table
  ignore_timestamp = false

[[inputs.disk]]
name_override = "metrics_disk"

[[inputs.diskio]]
name_override = "metrics_diskio"

# Read metrics about cpu usage
[[inputs.cpu]]
  name_override = "metrics_cpu"
  ## Whether to report per-cpu stats or not
  percpu = true
  ## Whether to report total system cpu stats or not
  totalcpu = true
  ## If true, collect raw CPU time metrics
  collect_cpu_time = false
  ## If true, compute and report the sum of all non-idle CPU states
  ## NOTE: The resulting 'time_active' field INCLUDES 'iowait'!
  report_active = false
  ## If true and the info is available then add core_id and physical_id tags
  core_tags = false

# Merge metrics into multifield metrics by series key
[[aggregators.merge]]
  ## If true, the original metric will be dropped by the
  ## aggregator and will not get sent to the output plugins.
  drop_original = true

[[outputs.influxdb_v2]]
  urls = ["${QUESTDB_HTTP_ENDPOINT}"]

  # if using QuestDB Enterprise, you can provide an HTTP token for authentication
  token = "${QUESTDB_HTTP_TOKEN}"

  # If using basic auth instead of a QuestDB Enterprise HTTP token, you can base64 enconde
  # your user and password separated by a colon, as in `user:password` and use that as the
  # token in the header for basic auth
  # http_headers = {"Authorization"="Basic ${QUESTDB_HTTP_TOKEN}"} 

  bucket = "questdb-metrics"


  content_encoding = "identity"  # Important to ensuring no gzip encoding
  # This is in case you are self-managing QuestDB under TLS with a self-signed certificate
  insecure_skip_verify = ${QUESTDB_SKIP_TLS_VERIFICATION}

